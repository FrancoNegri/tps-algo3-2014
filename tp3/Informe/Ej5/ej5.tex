\subsection{Idea General}

Para la meta-heurística de GRASP, trataremos de combinar el algoritmo goloso previamente implementado y las diferentes búsquedas locales también previamente implementadas, para así mejorar aun mas las respuestas obtenidas.

La idea es la siguiente, para cada paso del algoritmo, correremos una versión modificada del goloso de manera tal de permitir cierta aleatoriedad en los resultados. El algoritmo goloso será modificado de la siguiente manera:

\begin{algorithm}
  \begin{algorithmic}[1]\parskip=1mm
 \caption{ Goloso()}
 		\STATE{Numero los vértices de $1$ a $n$} 
		\STATE{Creo una cantidad $k$ de conjuntos donde iré guardando vértices}
 		\STATE{Para cada nodo $i$ de $1$ a $n$: }
		\STATE{\quad Para cada conjunto}
			\STATE{\quad\quad Sumo todos los pesos de las aristas de ($i$,$j$) con $j$, los vértices que están en el conjunto}
 		\STATE{\quad De los mejores $\alpha$ resultados obtenidos en el paso anterior, tomo uno al azar y pongo a $i$ en ese conjunto}
		\STATE{Devuelvo la respuesta}
\end{algorithmic}
\end{algorithm} 

Luego de esto se desprende que la RCL (restricted candidate list) para cada nodo serán los $\alpha$ conjuntos para los cuales el peso es menor que agregarlo en cualquier otro conjunto. Notar que si $\alpha=1$ entonces estaríamos obteniendo el mismo algoritmo goloso que en el apartado anterior. En cambio, si tomo $\alpha = k$ (esto es, tomo los $k$ mejores resultados, o sea todos), estaría generando una solución completamente aleatoria. Cualquier solución en medio tomará una solución golosa, pero con cierto grado de aleatoriedad.

Otro posible criterio que consideramos fue buscar para cada nodo cual era el conjunto que minimizaba el peso de agregarlo en el mismo, y luego agregar en su RCL todos los conjuntos que estuvieran un porcentaje $\beta$ por sobre ese valor.

Finalmente y por cuestiones de tiempos se decidió solo implementar el primer algoritmo goloso descripto anteriormente.

Luego, a la solución obtenida por el algoritmo goloso randomizado, se le aplicarán una o varias de las búsquedas locales implementadas, en un intento de acercarnos aún más a la respuesta exacta.

Como criterio de corte se correrá el goloso aleatorizado y la búsqueda local hasta que luego de que un número $z$, a determinar, de intentos no haya sido posible mejorar la solución. En este punto se entrega la mejor respuesta obtenida hasta el momento.

Teniendo a nuestra disposición tres búsquedas locales distintas, decidimos desarrollar tres GRASPs de tal manera que combinen de forma diferente estas búsquedas. El primero sólo utiliza la búsqueda local $1$, el segundo utiliza las tres búsquedas locales en orden descendente, es decir, primero la $3$, luego la $2$ y por último la $1$, y finalmente, el tercer y último GRASP utiliza dos búsquedas locales, en primer lugar la $3$ y luego la $1$. A continuación se formaliza de manera más precisa los algoritmos de cada uno:

\begin{algorithm}
  	\begin{algorithmic}[1]\parskip=1mm
		 \caption{ GRASP 1(SoluciónInicial) }
		 \STATE{while(true)}
		 	\STATE{\quad Corro el Algoritmo Goloso modificado}
		 	\STATE{\quad Utilizo búsqueda local 1 para mejorar la solución obtenida previamente}
		 	\STATE{\quad Si conseguí una mejor solución que antes, la guardo}
		 	\STATE{\quad Si tras $z$ iteraciones no se pudo conseguir una mejor solución}
		 	\STATE{\quad\quad Devuelvo la mejor solución encontrada}
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
  	\begin{algorithmic}[1]\parskip=1mm
		 \caption{ GRASP 2(SoluciónInicial) }
		 \STATE{while(true)}
		 	\STATE{\quad Corro el Algoritmo Goloso modificado}
		 	\STATE{\quad Utilizo búsqueda local 3 para mejorar la solución obtenida previamente}
		 	\STATE{\quad Utilizo búsqueda local 2 para mejorar aún más la solución obtenida previamente}
		 	\STATE{\quad Utilizo búsqueda local 1 para nuevamente mejorar la solución obtenida previamente}
		 	\STATE{\quad Si conseguí una mejor solución que antes, la guardo}
		 	\STATE{\quad Si tras $z$ iteraciones no se pudo conseguir una mejor solución}
		 	\STATE{\quad\quad Devuelvo la mejor solución encontrada}
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
  	\begin{algorithmic}[1]\parskip=1mm
		 \caption{ GRASP 3(SoluciónInicial) }
		 \STATE{while(true)}
		 	\STATE{\quad Corro el Algoritmo Goloso modificado}
		 	\STATE{\quad Utilizo búsqueda local 3 para mejorar la solución obtenida previamente}
		 	\STATE{\quad Utilizo búsqueda local 1 para mejorar aún más la solución obtenida previamente}
		 	\STATE{\quad Si conseguí una mejor solución que antes, la guardo}
		 	\STATE{\quad Si tras $z$ iteraciones no se pudo conseguir una mejor solución}
		 	\STATE{\quad\quad Devuelvo la mejor solución encontrada}
	\end{algorithmic}
\end{algorithm}

En estos tres casos $z$ puede ser un numero entero entre $1$ e infinito.

En el siguiente apartado de experimentación se intentarán calibrar tanto el parámetro $\alpha$ como el parámetro $z$ para así obtener los mejores resultados posibles con estas meta-heurísticas, tratando siempre de equilibrar tiempo de ejecución y exactitud de los resultados.

\subsection{Experimentación}

\subsubsection{Busqueda del $\alpha$ óptimo}

Para poder llegar a nuestro objetivo de encontrar los mejores parámetros $\alpha$ y $z$ a utilizar en las metaheurísticas, procederemos a hacer pruebas dejando fijo uno de los dos valores y variando el otro.
En primer lugar tomaremos un valor fijo arbitrario para $z$ y variaremos $\alpha$. Esta prueba consistirá en tomar un grafo y un $k$ fijo, y correr cada metaheurística con ese grafo como entrada y variando el parámetro $\alpha$. Una vez hecho esto, analizaremos para cuál valor de $\alpha$ se llegó a una mejor solución, es decir, el que más minimizó el peso total. Este parámetro $\alpha$ no podrá ser mayor que $k$ ya que si tengo $k$ conjuntos carece de sentido elegir entre los mejores $k'$ conjuntos siendo $k'>k$.

Tomamos como hipotesis que $\alpha$ depende de manera lineal a $k$, luego tomaremos $\alpha = 0.1 k,\alpha = 0.2 k,...,\alpha = k $, o lo que es lo mismo tomamos $\alpha$ igual al $10\%$ de k,$\alpha$ igual al $20\%$ de k, etc. Ademas simplemente para ver el comportamiento, tambien tomamos $\alpha$ igual a $1$, aunque este no sea tecnicamente un GRASP (Es un algoritmo goloso deterministico).

Realizamos un primer experimento que consistió en lo siguiente:

Como primer paso generamos un grafo completo de $500$ nodos, con pesos en las aristas aleatorios enteros de $1$ a $100$, con $k=100$. Consideramos este un caso lo suficientemente general y sin ningun tipo de patologías sobre el cual "entrenar" a nuestro algoritmo.

Luego para cada valor de $\alpha$ corrimos los tres GRASPs. Para cada uno de los GRASPs se obtuvo un $\alpha$ ganador, es decir, el $\alpha$ que obtubo una solución de peso menor que los demas $\alpha$s. Este proceso se realizó $100$ veces, siempre generando un grafo completo con pesos distintos en las aristas y en cada caso consiguiendo un $\alpha$ ganador. A continuación se presenta un gráfico, en cual se encuentran los tres GRASPs, que muestra para cada $\alpha$ cuántas de las $100$ veces "ganó". 

\includegraphics[scale=0.7]{Ej5/respuestasAlfa1.png}\\

Por lo que se ve en el gráfico, puede inferirse que para $\alpha=10$ se logran los mejores resultados en los tres GRASPs, al menos para el caso de 500 nodos. Respecto al tiempo que tardan los algoritmos, para los 100 grafos antes mencionados, también medimos el tiempo que tardaron, aquí se puede ver en promedio cuanto tardó cada uno:

\includegraphics[scale=0.7]{Ej5/tiemposAlfa.png}\\

No se aprecian diferencias significativas, salvo con $\alpha$ igual a $0 \%$, ya que este como hemos destacado antes, no es realmente una metaeuristica GRASP.

Observando las soluciones que se obtienen eligiendo el mejor valor para $\alpha$ y no otro valor, se obtienen mejoras que varían entre $1\%$ y $9\%$. Para ejemplificar, lo que queremos decir se muestra en el siguiente gráfico, los distintas soluciones que arrojó el GRASP 1 sobre un mismo grafo y variando el $\alpha$:

\includegraphics[scale=0.7]{Ej5/ejemploAlfa1.png}\\

Para comprobar de manera fehaciente que $\alpha$ esta relacionado de manera lineal con $k$ y que el tamaño del RCL siempre es el óptimo, realizamos este mismo experimento nuevamente pero esta vez con $1000$ nodos y $k=200$. A continuación el gráfico correspondiente.

\includegraphics[scale=0.7]{Ej5/respuestasAlfa2.png}\\

Los resultados son claros, nuevamente $\alpha=10$ es el ganador. Con esto podemos concluir con cierto grado de seguridad que el mejor valor para $\alpha$ es tomar el $10\%$ de $k$.

Además nuevamente tomado este valor de alfa, pueden verse como en general, las respuestas mejoran entre un $1 \%$ y un $10 \%$:

\includegraphics[scale=0.7]{Ej5/ejemploAlfa2.png}\\

Ahora la pregunta que sucede si el valor de $k$ es bajo. Para $k < 20$ obtenemos que $\alpha = 1$ obteniendo asi un algoritmo deterministico. Tomamos nuevamente $100$ grafos completos con $n=100$ con aristas aleatorias entre $1$ y $100$ y $k = 7$. Y graficamos de la misma manera que antes:

\includegraphics[scale=0.7]{Ej5/respuestasAlfa3.png}\\

Vemos que aunque el algoritmo en este caso no tiene ningun grado de aleatoriedad, continúa obteniendo las mejores respuestas. Luego se decide que para estos casos se permita que $\alpha$ sea igual a $1$.

\subsubsection{Busqueda del $z$ óptimo}

Una vez obtenido el mejor valor para $\alpha$, pasamos a buscar el mejor valor para $z$, con lo cual dejaremos fijo $\alpha=0.1k$ y variaremos el $z$.

Realizamos el segundo experimento, el cual consistió en tomar grafos completos de $250$ nodos y $k = 70$ variando $z$ desde $z = 4$ hasta $z = 40$ (para valores mayores de $z$ los tiempos de ejecución resultaban excesivos) para ver como respondía la metaheuristica ante estos cambios. Luego a los valores obtenidos de k-PMP se promedian para ver como varían en promedio los resultados al variar este parámetro.
Los resultados pueden verse aquí:

\includegraphics[scale=0.7]{Ej5/promedioZ.png}\\

\includegraphics[scale=0.7]{Ej5/tiemposZ.png}\\

Como se puede ver en el gráfico de tiempos, al aumentar la cantidad de iteraciones aumenta de manera lineal el tiempo de ejecución. Sin embargo las respuestas arrojadas por los algoritmos no mejoran con la misma pendiente, sino que lo hacen con una mucho mas moderada. Se decide tomar $z = 34$ para los tres GRASPs que se considera un valor que equilibra tanto las respuestas obtenidas, como un tiempo de ejecución apropiado. 

\subsubsection{Comparación entre Los Diferentes GRASPs}

Finalmente con estos valores para $\alpha$ y $z$, realizamos un último experimento para comparar las soluciones y los tiempos de cada GRASP.

Este último experimento consistió en, tomando $100$ nuevos grafos completos de $150$ nodos y con $k = 7$ y pesos aleatorios en sus aristas que varíen entre $1$ y $100$. Ver cual de los tres algoritmos es el que obtiene mejores resultados.

\includegraphics[scale=0.7]{Ej5/CompetenciaGRASPs1.png}\\

Dicho con palabras, entre los GRASPs, el GRASP 1 encontró 79 veces la menor solución (comparándolo con GRASP 2 y GRASP 3), el GRASP 2 la encontró 46 veces y el GRASP 3, 52. El hecho de que la suma de mayor a $100$ proviene de que en varias ocasiones mas de un GRASP encontró la menor solución.

Realizamos la misma experimentación para $100$ grafos de $250$ nodos, $k = 40$ y para otros $100$ grafos de $500$ nodos, $k = 70$:

\includegraphics[scale=0.7]{Ej5/CompetenciaGRASPs2.png}\\

\includegraphics[scale=0.7]{Ej5/CompetenciaGRASPs3.png}\\

Luego, tras todo este testeo podemos concluir que el GRASP $1$ es mejor para un numero mayor de casos que los otros dos algoritmos implementados.

En la sección siguiente utilizaremos el GRASP $1$ y lo compararemos contra los otros algoritmos implementados. Así podremos obtener resultados mas precisos de cuanto por encima de la solución exacta se encuentra, sobre que tipo de grafos es conveniente usarlo, etc.